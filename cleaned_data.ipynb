{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a3d9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon\n",
    "from geoalchemy2 import Geometry, WKTElement\n",
    "import matplotlib.pyplot as plt\n",
    "import database_connect as dc\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def create_wkt_element(geom, srid):\n",
    "    if geom.geom_type == 'Polygon':\n",
    "        geom = MultiPolygon([geom])\n",
    "    return WKTElement(geom.wkt, srid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d237bc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SA2 Data\n",
    "\n",
    "SA2 = gpd.read_file(\"SA2_2016_AUST/SA2_2016_AUST.shp\")\n",
    "\n",
    "# Make all column names lowercase\n",
    "SA2.columns = SA2.columns.str.lower()\n",
    "\n",
    "# Filter rows that are only part of Greater Sydney\n",
    "SA2 = SA2[SA2[\"gcc_name16\"].str.contains(\"Greater Sydney\") == True]\n",
    "\n",
    "# Removing unnecessary columns\n",
    "SA2 = SA2.drop(columns=['gcc_code16', 'gcc_name16', 'ste_code16', 'ste_name16'])\n",
    "\n",
    "# Checked for entries with no geometry, which are then removed\n",
    "null_geom = []\n",
    "\n",
    "for index, row in SA2.iterrows():\n",
    "    if row['geometry'] is None:\n",
    "        null_geom.append(index)\n",
    "\n",
    "SA2.drop(null_geom, axis=0, inplace=True)\n",
    "\n",
    "# Convert the values from object to more usable forms\n",
    "SA2['sa2_main16'] = SA2['sa2_main16'].astype('int64')\n",
    "SA2['sa2_5dig16'] = SA2['sa2_5dig16'].astype('int64')\n",
    "SA2['sa2_name16'] = SA2['sa2_name16'].astype('string')\n",
    "SA2['sa3_code16'] = SA2['sa3_code16'].astype('int64')\n",
    "SA2['sa3_name16'] = SA2['sa3_name16'].astype('string')\n",
    "SA2['sa4_code16'] = SA2['sa4_code16'].astype('int64')\n",
    "SA2['sa4_name16'] = SA2['sa4_name16'].astype('string')\n",
    "\n",
    "# make the column names neater - remove the 16 from the column headings, as we kow all the data is from 2016\n",
    "SA2.rename(\n",
    "    columns={'sa2_main16': 'sa2_code', 'sa2_5dig16': 'sa2_5digit', 'sa2_name16': 'sa2_name', 'sa3_code16': 'sa3_code',\n",
    "             'sa3_name16': 'sa3_name', 'sa4_code16': 'sa4_code', 'sa4_name16': 'sa4_name', 'areasqkm16': 'areasqkm'},\n",
    "    inplace=True)\n",
    "\n",
    "# convert geometry into a version that postGIS likes\n",
    "srid = 4283  # Change ID to Australian coordinate system\n",
    "\n",
    "SA2['geom'] = SA2['geometry'].apply(lambda x: create_wkt_element(x, srid))  # converting to WKT format\n",
    "SA2 = SA2.drop(columns=\"geometry\")  # deleting the old copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04697aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Neighbours data\n",
    "\n",
    "neighbours = pd.read_csv(\"Neighbourhoods.csv\")\n",
    "\n",
    "# Summing all the ages groups into one 'young people' column\n",
    "column_names = ['0-4', '5-9', '10-14', '15-19']\n",
    "neighbours['total_young_people'] = neighbours[column_names].sum(axis=1)\n",
    "\n",
    "# remove unnecessary index and businessses column. Remove the individual age columns now that we have a sum\n",
    "neighbours = neighbours.drop(columns=['index', 'number_of_businesses', '0-4', '5-9', '10-14', '15-19'])\n",
    "\n",
    "# remove punctuation from the random ones that have commas\n",
    "neighbours['population'] = neighbours['population'].str.replace(r'[^\\w\\s]+', '')\n",
    "neighbours['number_of_dwellings'] = neighbours['number_of_dwellings'].str.replace(r'[^\\w]+', '')\n",
    "\n",
    "# cast them all as nice data types\n",
    "neighbours['area_name'] = neighbours['area_name'].astype('string')\n",
    "neighbours['population'] = neighbours['population'].astype('float')\n",
    "neighbours['number_of_dwellings'] = neighbours['number_of_dwellings'].astype('float')\n",
    "\n",
    "# set empty cells to NaN using numpy\n",
    "neighbours = neighbours.replace('', np.nan, regex=True)\n",
    "\n",
    "# remove regions not an sa2\n",
    "not_sa2_region = []\n",
    "for index, row in neighbours.iterrows():\n",
    "    if row['area_id'] not in list(SA2['sa2_code']):\n",
    "        not_sa2_region.append(index)\n",
    "\n",
    "neighbours.drop(not_sa2_region, axis=0, inplace=True)\n",
    "\n",
    "neighbours.rename(\n",
    "    columns={'area_id': 'sa2_code', 'area_name': 'sa2_name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b42eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Business data\n",
    "\n",
    "business_stats = pd.read_csv(\"BusinessStats.csv\")\n",
    "\n",
    "# Dropping business sectors that are not of intrest\n",
    "business_stats = business_stats.drop(columns=['public_administration_and_safety', 'transport_postal_and_warehousing',\n",
    "                                              'agriculture_forestry_and_fishing'])\n",
    "\n",
    "# remove regions not an sa2\n",
    "not_sa2_region = []\n",
    "for index, row in business_stats.iterrows():\n",
    "    if row['area_id'] not in list(SA2['sa2_code']):\n",
    "        not_sa2_region.append(index)\n",
    "\n",
    "business_stats.drop(not_sa2_region, axis=0, inplace=True)\n",
    "# cast as string\n",
    "business_stats['area_name'] = business_stats['area_name'].astype('string')\n",
    "\n",
    "business_stats.rename(\n",
    "    columns={'area_id': 'sa2_code', 'area_name': 'sa2_name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3df3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Break and Enter data\n",
    "\n",
    "break_and_enter = gpd.read_file(\"bande/BreakEnterDwelling_JanToDec2021.shp\")\n",
    "\n",
    "# make all columns lower case\n",
    "break_and_enter.columns = break_and_enter.columns.str.lower()\n",
    "\n",
    "# cast density as string\n",
    "break_and_enter['density'] = break_and_enter['density'].astype('string')\n",
    "\n",
    "# change geometry datatype as with SA2 data\n",
    "srid = 4283  # this is the id of the Australian coordinate system\n",
    "break_and_enter['geom'] = break_and_enter['geometry'].apply(lambda x: create_wkt_element(x, srid))  # applying the function\n",
    "break_and_enter = break_and_enter.drop(columns=['contour', 'orig_fid', \"geometry\"]) # removing columns that are not needed\n",
    "\n",
    "# rename columns to correct formatting\n",
    "break_and_enter.rename(\n",
    "    columns={'shape_leng': 'shape_length', 'objectid': 'object_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9831b5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Catchments data\n",
    "\n",
    "# reading in all files\n",
    "catchments_future = gpd.read_file(\"catchments/catchments_future.shp\")\n",
    "catchments_primary = gpd.read_file(\"catchments/catchments_primary.shp\")\n",
    "catchments_secondary = gpd.read_file(\"catchments/catchments_secondary.shp\")\n",
    "\n",
    "# combine the 3 catchment shapefiles into one and remove unnecessary columns\n",
    "catchments_all_rows = pd.concat([catchments_primary, catchments_secondary])\n",
    "catchments_all_rows.drop(columns=['PRIORITY'], inplace=True)\n",
    "catchments_all_rows = pd.concat([catchments_all_rows, catchments_future])\n",
    "catchments_all_rows.drop(columns=['ADD_DATE'], inplace=True)\n",
    "\n",
    "# make all rows and columns lower case \n",
    "catchments_all_rows.columns = catchments_all_rows.columns.str.lower()\n",
    "\n",
    "catchments_all_rows['use_id'] = catchments_all_rows['use_id'].astype('int64')\n",
    "catchments_all_rows['catch_type'] = catchments_all_rows['catch_type'].astype('string')\n",
    "catchments_all_rows['use_desc'] = catchments_all_rows['use_desc'].astype('string')\n",
    "\n",
    "# boollean conversion for all rows\n",
    "catchments_all_rows[\n",
    "    ['kindergart', 'year1', 'year2', 'year3', 'year4', 'year5', 'year6', 'year7', 'year8', 'year9', 'year10', 'year11',\n",
    "     'year12']] = catchments_all_rows[\n",
    "    ['kindergart', 'year1', 'year2', 'year3', 'year4', 'year5', 'year6', 'year7', 'year8', 'year9', 'year10', 'year11',\n",
    "     'year12']].eq('Y').mul(1)\n",
    "\n",
    "# cast again\n",
    "catchments_all_rows['kindergart'] = catchments_all_rows['kindergart'].astype('int64')\n",
    "catchments_all_rows['year1'] = catchments_all_rows['year1'].astype('int64')\n",
    "catchments_all_rows['year2'] = catchments_all_rows['year2'].astype('int64')\n",
    "catchments_all_rows['year3'] = catchments_all_rows['year3'].astype('int64')\n",
    "catchments_all_rows['year4'] = catchments_all_rows['year4'].astype('int64')\n",
    "catchments_all_rows['year5'] = catchments_all_rows['year5'].astype('int64')\n",
    "catchments_all_rows['year6'] = catchments_all_rows['year6'].astype('int64')\n",
    "catchments_all_rows['year7'] = catchments_all_rows['year7'].astype('int64')\n",
    "catchments_all_rows['year8'] = catchments_all_rows['year8'].astype('int64')\n",
    "catchments_all_rows['year9'] = catchments_all_rows['year9'].astype('int64')\n",
    "catchments_all_rows['year10'] = catchments_all_rows['year10'].astype('int64')\n",
    "catchments_all_rows['year11'] = catchments_all_rows['year11'].astype('int64')\n",
    "catchments_all_rows['year12'] = catchments_all_rows['year12'].astype('int64')\n",
    "\n",
    "# make polygons nice\n",
    "catchments_all_rows['geom'] = catchments_all_rows['geometry'].apply(lambda x: create_wkt_element(x, srid))  # applying the function\n",
    "catchments_all_rows = catchments_all_rows.drop(columns=\"geometry\")  # deleting the old copy\n",
    "\n",
    "#\n",
    "catchments_all_rows.rename(\n",
    "    columns={'kindergart': 'kindergarten'}, inplace=True)\n",
    "\n",
    "#\n",
    "aggregation_functions = {'use_id': 'first', 'kindergarten': 'sum', 'year1': 'sum', 'year2': 'sum', 'year3': 'sum',\n",
    "                         'year4': 'sum',\n",
    "                         'year5': 'sum', 'year6': 'sum', 'year7': 'sum', 'year8': 'sum', 'year9': 'sum',\n",
    "                         'year10': 'sum', 'year11': 'sum', 'year12': 'sum', 'catch_type': 'first',\n",
    "                         'use_desc': 'first', 'geom': 'first'}\n",
    "catchments_all_rows = catchments_all_rows.groupby(catchments_all_rows['use_id']).aggregate(aggregation_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cb6468",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Walking count sites data\n",
    "\n",
    "walking_count_sites = gpd.read_file(\"Walking_count_sites.geojson\")\n",
    "\n",
    "walking_count_sites.columns = walking_count_sites.columns.str.lower()\n",
    "\n",
    "walking_count_sites['location'] = walking_count_sites['location'].astype('string')\n",
    "walking_count_sites['sitedescription'] = walking_c_sites['sitedescription'].astype('string')\n",
    "\n",
    "walking_count_sites['geom'] = walking_count_sites['geometry'].apply(lambda x: WKTElement(x.wkt, srid=srid))\n",
    "walking_count_sites.rename(\n",
    "    columns={'objectid': 'object_id', 'sitedescription': 'site_description', 'geometry': 'geom'}, inplace=True)\n",
    "\n",
    "not_in_walking_sites = []\n",
    "for index, row in walking_counts.iterrows():\n",
    "    if row['site_id'] not in list(walking_c_sites['site_id']):\n",
    "        not_in_walking_sites.append(index)\n",
    "\n",
    "walking_counts.drop(not_in_walking_sites, axis=0, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
